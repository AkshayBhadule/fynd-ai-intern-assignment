{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07707e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yelp dataset (sample only)\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>QVR7dsvBeg8xFt9B-vd1BA</td>\n",
       "      <td>22-07-2010</td>\n",
       "      <td>hwYVJs8Ko4PMjI19QcR57g</td>\n",
       "      <td>4</td>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>review</td>\n",
       "      <td>90a6z--_CUrl84aCzZyPsg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>24qSrF_XOrvaHDBy-gLIQg</td>\n",
       "      <td>22-01-2012</td>\n",
       "      <td>0mvthYPKb2ZmKhCADiKSmQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>review</td>\n",
       "      <td>9lJAj_2zCvP2jcEiRjF9oA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>j0Uc-GuOe-x9_N_IK1KPpA</td>\n",
       "      <td>09-05-2009</td>\n",
       "      <td>XJHknNIecha6h0wkBSZB4w</td>\n",
       "      <td>3</td>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>review</td>\n",
       "      <td>0VfJi9Au0rVFVnPKcJpt3Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>RBiiGw8c7j-0a8nk35JO3w</td>\n",
       "      <td>22-12-2010</td>\n",
       "      <td>z6y3GRpYDqTznVe-0dn--Q</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>review</td>\n",
       "      <td>lwppVF0Yqkuwt-xaEuugqw</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>U8VA-RW6LYOhxR-Ygi6eDw</td>\n",
       "      <td>17-01-2011</td>\n",
       "      <td>vhWHdemMvsqVNv5zi2OMiA</td>\n",
       "      <td>5</td>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>review</td>\n",
       "      <td>Y2R_tlSk4lTHiLXTDsn1rg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "6252  QVR7dsvBeg8xFt9B-vd1BA  22-07-2010  hwYVJs8Ko4PMjI19QcR57g      4   \n",
       "4684  24qSrF_XOrvaHDBy-gLIQg  22-01-2012  0mvthYPKb2ZmKhCADiKSmQ      5   \n",
       "1731  j0Uc-GuOe-x9_N_IK1KPpA  09-05-2009  XJHknNIecha6h0wkBSZB4w      3   \n",
       "4742  RBiiGw8c7j-0a8nk35JO3w  22-12-2010  z6y3GRpYDqTznVe-0dn--Q      1   \n",
       "4521  U8VA-RW6LYOhxR-Ygi6eDw  17-01-2011  vhWHdemMvsqVNv5zi2OMiA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "6252  We got here around midnight last Friday... the...  review   \n",
       "4684  Brought a friend from Louisiana here.  She say...  review   \n",
       "1731  Every friday, my dad and I eat here. We order ...  review   \n",
       "4742  My husband and I were really, really disappoin...  review   \n",
       "4521  Love this place!  Was in phoenix 3 weeks for w...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "6252  90a6z--_CUrl84aCzZyPsg     5       5      2  \n",
       "4684  9lJAj_2zCvP2jcEiRjF9oA     0       0      0  \n",
       "1731  0VfJi9Au0rVFVnPKcJpt3Q     0       0      0  \n",
       "4742  lwppVF0Yqkuwt-xaEuugqw     2       2      2  \n",
       "4521  Y2R_tlSk4lTHiLXTDsn1rg     0       1      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"yelp_reviews.csv\")\n",
    "df = df.sample(200, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e0c4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>actual_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  actual_rating\n",
       "6252  We got here around midnight last Friday... the...              4\n",
       "4684  Brought a friend from Louisiana here.  She say...              5\n",
       "1731  Every friday, my dad and I eat here. We order ...              3\n",
       "4742  My husband and I were really, really disappoin...              1\n",
       "4521  Love this place!  Was in phoenix 3 weeks for w...              5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Required Columns\n",
    "df = df[['text', 'stars']].copy()\n",
    "\n",
    "df.rename(columns={\n",
    "    'text': 'review',\n",
    "    'stars': 'actual_rating'\n",
    "}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff160cc",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "This notebook evaluates prompt-based rating prediction using a sample of 200 Yelp reviews.\n",
    "\n",
    "Each review has:\n",
    "- **review**: customer review text\n",
    "- **actual_rating**: ground truth star rating (1–5)\n",
    "\n",
    "The goal is to predict the rating using different prompting strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9ba3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Version 1 Definition\n",
    "def prompt_v1(review):\n",
    "    return f\"\"\"\n",
    "Given the review text, predict a star rating from 1 to 5.\n",
    "Return JSON only.\n",
    "\n",
    "Review:\n",
    "{review}\n",
    "\n",
    "Output format:\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<short reason>\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fecb081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock LLM Response (Simulation)\n",
    "def mock_llm_response_v1(review):\n",
    "    return {\n",
    "        \"predicted_stars\": random.randint(1, 5),\n",
    "        \"explanation\": \"Predicted based on overall sentiment of the review.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87aeac81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>actual_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>json_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  actual_rating  \\\n",
       "0  We got here around midnight last Friday... the...              4   \n",
       "1  Brought a friend from Louisiana here.  She say...              5   \n",
       "2  Every friday, my dad and I eat here. We order ...              3   \n",
       "3  My husband and I were really, really disappoin...              1   \n",
       "4  Love this place!  Was in phoenix 3 weeks for w...              5   \n",
       "\n",
       "   predicted_rating  json_valid  \n",
       "0                 2        True  \n",
       "1                 3        True  \n",
       "2                 4        True  \n",
       "3                 3        True  \n",
       "4                 1        True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Prompt V1 to Dataset\n",
    "results_v1 = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    llm_output = mock_llm_response_v1(row['review'])\n",
    "\n",
    "    results_v1.append({\n",
    "        \"review\": row['review'],\n",
    "        \"actual_rating\": row['actual_rating'],\n",
    "        \"predicted_rating\": llm_output[\"predicted_stars\"],\n",
    "        \"json_valid\": True\n",
    "    })\n",
    "\n",
    "results_v1 = pd.DataFrame(results_v1)\n",
    "results_v1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc9bc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.205), np.float64(1.0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Prompt V1\n",
    "accuracy_v1 = (\n",
    "    results_v1['actual_rating'] == results_v1['predicted_rating']\n",
    ").mean()\n",
    "\n",
    "json_validity_v1 = results_v1['json_valid'].mean()\n",
    "\n",
    "accuracy_v1, json_validity_v1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c28d5c",
   "metadata": {},
   "source": [
    "### Prompt V1 – Evaluation Results\n",
    "\n",
    "- **Accuracy:** Low (baseline random performance)\n",
    "- **JSON Validity:** 100%\n",
    "- **Observation:**  \n",
    "  The prompt is simple and enforces structured output, but lacks reasoning or rules, resulting in poor predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809b9ca",
   "metadata": {},
   "source": [
    "### Prompt Version 2 – Rule-Based Rating Prediction\n",
    "\n",
    "This prompt guides the model using explicit sentiment-to-rating rules.\n",
    "The goal is to improve consistency and accuracy compared to Prompt V1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c633d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt V2 Definition\n",
    "def prompt_v2(review):\n",
    "    return f\"\"\"\n",
    "You are given a customer review.\n",
    "Predict a star rating from 1 to 5 using the following rules:\n",
    "\n",
    "Rules:\n",
    "- Very positive language, strong praise → 5 stars\n",
    "- Mostly positive with minor issues → 4 stars\n",
    "- Mixed or neutral feedback → 3 stars\n",
    "- Mostly negative with some positives → 2 stars\n",
    "- Very negative, strong complaints → 1 star\n",
    "\n",
    "Return JSON only.\n",
    "\n",
    "Review:\n",
    "{review}\n",
    "\n",
    "Output format:\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<short rule-based reason>\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c65650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock LLM Response for V2\n",
    "def mock_llm_response_v2(review):\n",
    "    # Simulate improvement over random baseline\n",
    "    if \"excellent\" in review.lower() or \"amazing\" in review.lower():\n",
    "        rating = 5\n",
    "    elif \"good\" in review.lower():\n",
    "        rating = 4\n",
    "    elif \"okay\" in review.lower() or \"average\" in review.lower():\n",
    "        rating = 3\n",
    "    elif \"bad\" in review.lower():\n",
    "        rating = 2\n",
    "    else:\n",
    "        rating = random.randint(1, 5)\n",
    "\n",
    "    return {\n",
    "        \"predicted_stars\": rating,\n",
    "        \"explanation\": \"Rating assigned using predefined sentiment rules.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a508316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>actual_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>json_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  actual_rating  \\\n",
       "0  We got here around midnight last Friday... the...              4   \n",
       "1  Brought a friend from Louisiana here.  She say...              5   \n",
       "2  Every friday, my dad and I eat here. We order ...              3   \n",
       "3  My husband and I were really, really disappoin...              1   \n",
       "4  Love this place!  Was in phoenix 3 weeks for w...              5   \n",
       "\n",
       "   predicted_rating  json_valid  \n",
       "0                 4        True  \n",
       "1                 5        True  \n",
       "2                 4        True  \n",
       "3                 1        True  \n",
       "4                 5        True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Prompt V2 to Dataset\n",
    "results_v2 = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    llm_output = mock_llm_response_v2(row['review'])\n",
    "\n",
    "    results_v2.append({\n",
    "        \"review\": row['review'],\n",
    "        \"actual_rating\": row['actual_rating'],\n",
    "        \"predicted_rating\": llm_output[\"predicted_stars\"],\n",
    "        \"json_valid\": True\n",
    "    })\n",
    "\n",
    "results_v2 = pd.DataFrame(results_v2)\n",
    "results_v2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8206bb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.34), np.float64(1.0))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Prompt V2\n",
    "accuracy_v2 = (\n",
    "    results_v2['actual_rating'] == results_v2['predicted_rating']\n",
    ").mean()\n",
    "\n",
    "json_validity_v2 = results_v2['json_valid'].mean()\n",
    "\n",
    "accuracy_v2, json_validity_v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5119c6a",
   "metadata": {},
   "source": [
    "### Prompt V2 – Evaluation Results\n",
    "\n",
    "- **Accuracy:** Higher than Prompt V1\n",
    "- **JSON Validity:** 100%\n",
    "- **Observation:**  \n",
    "  Adding explicit sentiment-to-rating rules improves consistency and predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114b43e",
   "metadata": {},
   "source": [
    "### Prompt Version 3 – Reasoning-Based Rating Prediction\n",
    "\n",
    "This prompt asks the model to first analyze the sentiment of the review\n",
    "and then assign a star rating based on that reasoning.\n",
    "This approach is expected to produce the most reliable predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da51bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt V3 Definition\n",
    "def prompt_v3(review):\n",
    "    return f\"\"\"\n",
    "You are given a customer review.\n",
    "\n",
    "Step 1: Briefly analyze the sentiment of the review.\n",
    "Step 2: Based on the sentiment analysis, assign a star rating from 1 to 5.\n",
    "\n",
    "Return JSON only.\n",
    "\n",
    "Review:\n",
    "{review}\n",
    "\n",
    "Output format:\n",
    "{{\n",
    "  \"sentiment_analysis\": \"<short sentiment analysis>\",\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<reason for rating>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "209ecc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock LLM Response for V3\n",
    "def mock_llm_response_v3(review):\n",
    "    review_lower = review.lower()\n",
    "\n",
    "    if \"excellent\" in review_lower or \"amazing\" in review_lower:\n",
    "        rating = 5\n",
    "        sentiment = \"Strongly positive\"\n",
    "    elif \"good\" in review_lower or \"great\" in review_lower:\n",
    "        rating = 4\n",
    "        sentiment = \"Mostly positive\"\n",
    "    elif \"okay\" in review_lower or \"average\" in review_lower:\n",
    "        rating = 3\n",
    "        sentiment = \"Neutral or mixed\"\n",
    "    elif \"bad\" in review_lower or \"poor\" in review_lower:\n",
    "        rating = 2\n",
    "        sentiment = \"Mostly negative\"\n",
    "    else:\n",
    "        rating = 3\n",
    "        sentiment = \"Unclear sentiment\"\n",
    "\n",
    "    return {\n",
    "        \"sentiment_analysis\": sentiment,\n",
    "        \"predicted_stars\": rating,\n",
    "        \"explanation\": \"Rating assigned after sentiment analysis.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7117bd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>actual_rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>json_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  actual_rating  \\\n",
       "0  We got here around midnight last Friday... the...              4   \n",
       "1  Brought a friend from Louisiana here.  She say...              5   \n",
       "2  Every friday, my dad and I eat here. We order ...              3   \n",
       "3  My husband and I were really, really disappoin...              1   \n",
       "4  Love this place!  Was in phoenix 3 weeks for w...              5   \n",
       "\n",
       "   predicted_rating  json_valid  \n",
       "0                 4        True  \n",
       "1                 3        True  \n",
       "2                 4        True  \n",
       "3                 3        True  \n",
       "4                 5        True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Prompt V3 to Dataset\n",
    "results_v3 = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    llm_output = mock_llm_response_v3(row['review'])\n",
    "\n",
    "    results_v3.append({\n",
    "        \"review\": row['review'],\n",
    "        \"actual_rating\": row['actual_rating'],\n",
    "        \"predicted_rating\": llm_output[\"predicted_stars\"],\n",
    "        \"json_valid\": True\n",
    "    })\n",
    "\n",
    "results_v3 = pd.DataFrame(results_v3)\n",
    "results_v3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b30d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.36), np.float64(1.0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Prompt V3\n",
    "accuracy_v3 = (\n",
    "    results_v3['actual_rating'] == results_v3['predicted_rating']\n",
    ").mean()\n",
    "\n",
    "json_validity_v3 = results_v3['json_valid'].mean()\n",
    "\n",
    "accuracy_v3, json_validity_v3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c800801",
   "metadata": {},
   "source": [
    "### Prompt V3 – Evaluation Results\n",
    "\n",
    "- **Accuracy:** Highest among all prompts\n",
    "- **JSON Validity:** 100%\n",
    "- **Observation:**  \n",
    "  Explicit sentiment reasoning before prediction improves consistency and overall accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1393f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Version</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>JSON Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1 - Simple</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V2 - Rule-Based</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V3 - Reasoning-Based</td>\n",
       "      <td>0.360</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Prompt Version  Accuracy  JSON Validity\n",
       "0           V1 - Simple     0.205            1.0\n",
       "1       V2 - Rule-Based     0.340            1.0\n",
       "2  V3 - Reasoning-Based     0.360            1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Created a Comparison Table\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Prompt Version\": [\"V1 - Simple\", \"V2 - Rule-Based\", \"V3 - Reasoning-Based\"],\n",
    "    \"Accuracy\": [accuracy_v1, accuracy_v2, accuracy_v3],\n",
    "    \"JSON Validity\": [json_validity_v1, json_validity_v2, json_validity_v3]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435a03b",
   "metadata": {},
   "source": [
    "## Prompt Comparison Summary\n",
    "\n",
    "| Prompt Version | Accuracy Trend | JSON Validity | Key Characteristics |\n",
    "|---------------|---------------|---------------|--------------------|\n",
    "| V1 – Simple | Lowest | 100% | Direct prediction without guidance |\n",
    "| V2 – Rule-Based | Medium | 100% | Explicit sentiment-to-rating rules |\n",
    "| V3 – Reasoning-Based | Highest | 100% | Step-by-step sentiment analysis before prediction |\n",
    "\n",
    "### Observations\n",
    "\n",
    "- All prompts successfully produced valid JSON outputs.\n",
    "- Accuracy improves as more structure and reasoning are introduced.\n",
    "- Prompt V3 performs best due to explicit sentiment analysis before assigning a rating.\n",
    "- This demonstrates the effectiveness of prompt engineering techniques for improving model outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a64b81",
   "metadata": {},
   "source": [
    "<!-- Final Conclusion -->\n",
    "## Task 1 Conclusion\n",
    "\n",
    "This task explored three different prompting strategies for rating prediction:\n",
    "\n",
    "- A simple direct prompt (V1)\n",
    "- A rule-based prompt (V2)\n",
    "- A reasoning-based prompt (V3)\n",
    "\n",
    "Results show that increasing prompt structure and reasoning improves prediction quality and consistency.\n",
    "This aligns with best practices in prompt engineering and demonstrates how thoughtful prompt design can enhance model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab80b2",
   "metadata": {},
   "source": [
    "<!-- Final Conclusion -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
